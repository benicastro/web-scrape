# Import necessary modules/libraries
import scrapy


# Create Spider code
class GabSpider(scrapy.Spider):
    name = "gab_spider"
    start_urls = ["https://www.whiskyshop.com/scotch-whisky?item_availability=In+Stock"]

    def start_requests(self):
        headers = {
            "User-Agent": "Mozilla/5.0 (X11; Linux x86_64; rv:48.0) Gecko/20100101 Firefox/48.0"
        }
        for url in self.start_urls:
            yield scrapy.Request(url, headers=headers, callback=self.parse)

    def parse(self, response):
        for products in response.css("div.product-item-info"):
            try:
                yield {
                    "name": products.css("a.product-item-link::text").get(),
                    "price": products.css("span.price::text").get().replace("Â£", ""),
                    "link": products.css("a.product-item-link").attrib["href"],
                }
            except:
                yield {
                    "name": products.css("a.product-item-link::text").get(),
                    "price": "sold out",
                    "link": products.css("a.product-item-link").attrib["href"],
                }

        next_page = response.css("a.action.next").attrib["href"]
        if next_page is not None:
            yield response.follow(next_page, callback=self.parse)
